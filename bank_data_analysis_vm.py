# -*- coding: utf-8 -*-
"""Bank Data Analysis - VM

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t70tnZi0HTfuZLmsvjPfZzS6RgfPw2bo

#Importing Libraries to run the operations
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from sklearn.cluster import KMeans
from sklearn.cluster import KMeans
import statsmodels.api as sm
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import warnings
import seaborn as sns # for visualization
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import warnings

"""
### -> Determining class attribute in the dataset and identifying marketing purposes to correspond with the class attribute.

#Reflection

###*The class attribute for this dataset would be 'y'. The y column determines clients who subscribed to the term deposit. This class attribute satisfies the marketing purposes because this information helps the marketing agencies advertise their offers and interest rates to lure target customers based on their term deposit subscription.*
"""

bd = pd.read_csv('https://raw.githubusercontent.com/shstreuber/Data-Mining/master/data/BankMarketing.csv',sep=';')
bd

bd['education'].unique()

bd_education_noHS = bd[(bd['education'] == 'basic.4y') | (bd['education'] == 'basic.6y') | (bd['education'] == 'basic.9y')| (bd['education'] == 'unknown')| (bd['education'] == 'illiterate')]
bd_education_noHS

"""### -> Minimum, Maximum, Mean, Median, Mode, Q1, Q3, and Standard Deviation for the age and duration attributes belonging to customers who were contacted by telephone and customers who were contacted by cellphone.

#Reflection

###*The attribute with the smaller standard deviation of all is 'pdays'. The following outcome indicates population with no highschool education background have higher chances to be contacted by the bank markets. Population with highschool education background have high chances to be contacted as well, but population with no highschool education background have higher chances.*

#Minimum, Maximum, Mean, Median, Mode, Q1, Q3, and Standard Deviation for No High School
"""

bd_education_noHS.describe()

bd_education_HS = bd[(bd['education'] == 'high.school') | (bd['education'] == 'professional.course') | (bd['education'] == 'university.degree')]
bd_education_HS

"""#Minimum, Maximum, Mean, Median, Mode, Q1, Q3, and Standard Deviation for High School"""

bd_education_HS.describe()

"""#Building scatterplot against the class attribute and describing in detail about the assigned attributes correlated to the class attribute.





"""

bd['y_num'] = bd['y'].map(dict(yes=1, no=0))

bd_education_HS['y_num'] = bd_education_HS['y'].map(dict(yes=1, no=0))

bdHS = bd_education_HS[['pdays','duration','y_num']]
ax1 = bdHS.plot.scatter(x='duration',y='y_num',c='pdays')

"""
#Separating the dataset into 25% training data and 75% test data, and then preparing the training data to run with Neural Network and Random Forest classifier.

"""

unscaled_features = bd[['pdays','duration']]
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
unscaled_features_array = sc.fit_transform(unscaled_features.values)
scaled_features = pd.DataFrame(unscaled_features_array, index=unscaled_features.index, columns=unscaled_features.columns)
scaled_features.head()

"""#25% training data and 75% test data"""

from sklearn.model_selection import train_test_split
X = scaled_features
y = bd['y_num']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.75)

from sklearn.neural_network import MLPClassifier

# Initializing the multilayer perceptron
# running this with all the default settings, including a hidden_layer_sizes setting of 100 adn 200 maximum iterations. 
# Verbose is on so we can see how this runs.

mlp1 = MLPClassifier(verbose=1) # We are running this in verbose mode so we can see the output of each iteration.

mlp1.fit(X_train, y_train)

"""#Multilayer Perceptron Score"""

print (mlp1.score(X_test,y_test))

"""#Confusion Matrix"""

from sklearn.metrics import plot_confusion_matrix
plot_confusion_matrix(mlp1, X_test, y_test)

rf = RandomForestClassifier()
rf.get_params

rf.fit(X_train, y_train)

y_predrf = rf.predict(X_test)

"""#Accuracy Score"""

accuracy_score(y_test, y_predrf)

"""#Confusion Matrix"""

from sklearn.metrics import plot_confusion_matrix
plot_confusion_matrix(rf, X_test, y_test)

bd_num = bd[['pdays','duration']]

from sklearn.preprocessing import StandardScaler
sc = StandardScaler() 
bd_cluster = sc.fit_transform(bd_num.values) #calculate μ & σ (fit) and apply the transformation(transform)
bd_cluster

bd_cluster_norm = pd.DataFrame(bd_num,index=bd_num.index, columns=bd_num.columns)
bd_cluster_norm

from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=3, ).fit(bd_cluster_norm)
labels = kmeans.labels_
labels

"""
### -> What clusters are discovered? What bank marketing opportunities are achieved in these two populations?
#Reflection
###*There are two clusters discovered. It is closely associated. It explains that bank marketing opportunities are higher for people who have not been contacted than people who have already been contacted since new clients are offered more deals for banks to gain subscriptions.*"""

groups = {0: [], 1: [], 2: []} 
i = 0                                       
for index, row in bd.iterrows():      
    groups[labels[i]].append(index)        
    i += 1


for key, value in groups.items():           #
    print ('CLUSTER %i' % key)
    for Xvalue in value:
        print("    %s" % Xvalue)
    print('\n')

"""# 2."""

groups

"""#Density Based Clutering(DBSCAN)"""

## import data
from sklearn.datasets import make_moons
from sklearn import datasets

## import DBSCAN model
from sklearn.cluster import DBSCAN
from sklearn import metrics

plt.style.use('ggplot')

model_1 = DBSCAN(eps=0.25, min_samples=12).fit(X_test)
print(model_1) # model set-ups and parameters

model_1.get_params

labels_1=model_1.labels_
labels_1

model_1.fit_predict(X_test)

"""#Figure"""

fig, ax = plt.subplots(figsize=(8, 6))
ax.scatter(X_test['pdays'], X_test['duration'], c=model_1.labels_, s=140, alpha=0.9, cmap=plt.cm.Set1)

fig.show()

"""### -> So what political decisions could the bank's social network marketing manager make on the basis of classification and cluster analysis?
###*Upon the classification and cluster analysis, the bank marketing manager can make political decisions based on the population regarding their educational background. For instance, it can decide to support a political candidate by analyzing the type of population with or without a high school education background are supporting the political candidate more.*


"""